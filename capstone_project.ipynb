{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv.main import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Literal\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_CSE_ID= os.getenv(\"GOOGLE_CSE_ID\")\n",
    "GOOGLE_SEARCH_KEY= os.getenv(\"GOOGLE_SEARCH_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderState(TypedDict):\n",
    "    \"\"\"State representing the customer's order conversation.\"\"\"\n",
    "\n",
    "    # The chat conversation. This preserves the conversation history\n",
    "    # between nodes. The `add_messages` annotation indicates to LangGraph\n",
    "    # that state is updated by appending returned messages, not replacing\n",
    "    # them.\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "    # The customer's in-progress order.\n",
    "    order: list[str]\n",
    "\n",
    "    # Flag indicating that the order is placed and completed.\n",
    "    finished: bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIPADVISOR_SYSINT = (\n",
    "    \"system\",  # 'system' indicates the message is a system instruction.\n",
    "    \"You are a helpful and friendly Trip Advisor bot. A human will ask you for recommendations \"\n",
    "    \"and information about transportation to use, places to visit, activities to do, restaurants to eat at, and \"\n",
    "    \"accommodations to stay in. Your primary goal is to provide relevant and accurate information \"\n",
    "    \"based on the user's requests, helping them plan their trip effectively. \"\n",
    "    \"You can ask clarifying questions to better understand their preferences and needs. \"\n",
    "    \"Avoid engaging in off-topic discussions and focus solely on trip-related inquiries. \"\n",
    "    \"\\n\\n\"\n",
    "    \"You have access to several tools to assist the user:\"\n",
    "    \"\\n\"\n",
    "    \"- `search_places`: Use this tool to find information about specific places, attractions, \"\n",
    "    \"restaurants, or accommodations. The input should be a detailed query including location \"\n",
    "    \"and keywords describing what the user is looking for (e.g., 'best beaches in Barcelona', \"\n",
    "    \"'romantic restaurants near Sagrada Familia', 'budget-friendly hotels in the Gothic Quarter').\"\n",
    "    \"If the user asks for a list of places, ALWAYS respond with a \"\n",
    "    \"search_places tool call (no text) whose arguments include at least \"\n",
    "    '{\"query\": \"<user request>\"} . After the tool returns, summarise the results.'\n",
    "\n",
    "    \"\\n\"\n",
    "    \"- `get_place_details`: Use this tool to retrieve more detailed information about a specific \"\n",
    "    \"place identified by its unique ID (which you might have obtained from `search_places`). \"\n",
    "    \"The input should be the place ID.\"\n",
    "    \"\\n\"\n",
    "    \"- `get_directions`: Use this tool to provide directions between two locations. The input \"\n",
    "    \"should include the starting point and the destination.\"\n",
    "    \"\\n\"\n",
    "    \"- `translate_text`: Use this tool to translate text between languages. The input should \"\n",
    "    \"include the text to translate and the target language.\"\n",
    "    \"\\n\\n\"\n",
    "    \"When responding to the user, synthesize information from these tools into a coherent and \"\n",
    "    \"helpful answer. If a user asks for recommendations, use `search_places` with relevant keywords \"\n",
    "    \"and present a few options. You can then use `get_place_details` if the user expresses interest \"\n",
    "    \"in a specific option. If the user asks for how to get somewhere, use `get_directions`. If there's \"\n",
    "    \"a language barrier, offer to use `translate_text`.\"\n",
    "    \"\\n\\n\"\n",
    "    \"Remember to be polite and helpful throughout the interaction. If you cannot find information \"\n",
    "    \"related to the user's request, acknowledge this and suggest alternative ways you might be able to assist.\"\n",
    "    \"\\n\\n\"\n",
    "    \"If any of the tools are unavailable, you can break the fourth wall and tell the user that \"\n",
    "    \"they have not implemented them yet and should keep reading to do so.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WELCOME_MSG = \"Welcome to the TripoBot. Type `q` to quit. What is your dream trip? how much is your budget? what activity do you like to do? Do you like blind trip program?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "\n",
    "def chatbot(state: OrderState) -> OrderState:\n",
    "    \"\"\"The chatbot itself. A simple wrapper around the model's own chat interface.\"\"\"\n",
    "    message_history = [TRIPADVISOR_SYSINT] + state[\"messages\"]\n",
    "    return {\"messages\": [llm.invoke(message_history)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the initial graph based on our state definition.\n",
    "graph_builder = StateGraph(OrderState)\n",
    "\n",
    "# Add the chatbot function to the app graph as a node called \"chatbot\".\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# Define the chatbot node as the app entrypoint.\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "chat_graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "stream = BytesIO(chat_graph.get_graph().draw_mermaid_png())\n",
    "image = Image.open(stream).convert(\"RGBA\")\n",
    "image.save(\"test.png\")\n",
    "# with open(\"test.png\", \"w\") as f:\n",
    "#     f.write(str()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello, what can you do?', additional_kwargs={}, response_metadata={}, id='f09fd96d-120f-4688-99ad-4c798585653f'), AIMessage(content='Hello! I can help you plan your trip. I can provide recommendations and information about transportation, places to visit, activities, restaurants, and accommodations.\\n\\nTo give you the best recommendations, I need a little more information. Where are you planning to travel, and what are you interested in?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-10e5c983-a043-40c5-9dcd-c8483269fd7c-0', usage_metadata={'input_tokens': 501, 'output_tokens': 60, 'total_tokens': 561, 'input_token_details': {'cache_read': 0}})]}\n",
      "__________\n",
      "HumanMessage: Hello, what can you do?\n",
      "AIMessage: Hello! I can help you plan your trip. I can provide recommendations and information about transportation, places to visit, activities, restaurants, and accommodations.\n",
      "\n",
      "To give you the best recommendations, I need a little more information. Where are you planning to travel, and what are you interested in?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_msg = \"Hello, what can you do?\"\n",
    "state = chat_graph.invoke({\"messages\": [user_msg]})\n",
    "\n",
    "# The state object contains lots of information. Uncomment the print lines to see it all.\n",
    "print(state)\n",
    "print(\"_\"*10)\n",
    "\n",
    "# Note that the final state now has 2 messages. Our HumanMessage, and an additional AIMessage.\n",
    "for msg in state[\"messages\"]:\n",
    "    print(f\"{type(msg).__name__}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage: Hello, what can you do?\n",
      "AIMessage: Hello! I can help you plan your trip. I can provide recommendations and information about transportation, places to visit, activities, restaurants, and accommodations.\n",
      "\n",
      "To give you the best recommendations, I need a little more information. Where are you planning to travel, and what are you interested in?\n",
      "HumanMessage: Oh great, What is the best hotels in Paris?\n",
      "AIMessage: ```tool_code\n",
      "search_places({\"query\": \"best hotels in Paris\"})\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "user_msg = \"Oh great, What is the best hotels in Paris?\"\n",
    "\n",
    "state[\"messages\"].append(user_msg)\n",
    "state = chat_graph.invoke(state)\n",
    "\n",
    "# pprint(state)\n",
    "for msg in state[\"messages\"]:\n",
    "    print(f\"{type(msg).__name__}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def human_node(state: OrderState) -> OrderState:\n",
    "    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    print(\"Model:\", last_msg.content)\n",
    "\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # If it looks like the user is trying to quit, flag the conversation\n",
    "    # as over.\n",
    "    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n",
    "        state[\"finished\"] = True\n",
    "\n",
    "    return state | {\"messages\": [(\"user\", user_input)]}\n",
    "\n",
    "\n",
    "def chatbot_with_welcome_msg(state: OrderState) -> OrderState:\n",
    "    \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n",
    "\n",
    "    if state[\"messages\"]:\n",
    "        # If there are messages, continue the conversation with the Gemini model.\n",
    "        new_output = llm.invoke([TRIPADVISOR_SYSINT] + state[\"messages\"])\n",
    "    else:\n",
    "        # If there are no messages, start with the welcome message.\n",
    "        new_output = AIMessage(content=WELCOME_MSG)\n",
    "\n",
    "    return state | {\"messages\": [new_output]}\n",
    "\n",
    "\n",
    "# Start building a new graph.\n",
    "graph_builder = StateGraph(OrderState)\n",
    "\n",
    "# Add the chatbot and human nodes to the app graph.\n",
    "graph_builder.add_node(\"chatbot\", chatbot_with_welcome_msg)\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "\n",
    "# Start with the chatbot again.\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# The chatbot will always go to the human next.\n",
    "graph_builder.add_edge(\"chatbot\", \"human\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_exit_human_node(state: OrderState) -> Literal[\"chatbot\", \"__end__\"]:\n",
    "    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n",
    "    if state.get(\"finished\", False):\n",
    "        return END\n",
    "    else:\n",
    "        return \"chatbot\"\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
    "\n",
    "chat_with_human_graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chat_with_human_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mchat_with_human_graph\u001b[49m\u001b[38;5;241m.\u001b[39mget_graph()\u001b[38;5;241m.\u001b[39mdraw_mermaid_png()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chat_with_human_graph' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "chat_with_human_graph.get_graph().draw_mermaid_png()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Welcome to the TripoBot. Type `q` to quit. What is your dream trip? how much is your budget? what activity do you like to do? Do you like blind trip program?\n",
      "{'finished': True,\n",
      " 'messages': [AIMessage(content='Welcome to the TripoBot. Type `q` to quit. What is your dream trip? how much is your budget? what activity do you like to do? Do you like blind trip program?', additional_kwargs={}, response_metadata={}, id='22377184-9d87-4d91-ac8f-f16ccc4483b5'),\n",
      "              HumanMessage(content='q', additional_kwargs={}, response_metadata={}, id='c7d81602-02e6-4540-8352-62d18d030697')]}\n"
     ]
    }
   ],
   "source": [
    "# The default recursion limit for traversing nodes is 25 - setting it higher means\n",
    "# you can try a more complex order with multiple steps and round-trips (and you\n",
    "# can chat for longer!)\n",
    "config = {\"recursion_limit\": 25}\n",
    "\n",
    "# Remember that this will loop forever, unless you input `q`, `quit` or one of the\n",
    "# other exit terms defined in `human_node`.\n",
    "# Uncomment this line to execute the graph:\n",
    "state = chat_with_human_graph.invoke({\"messages\": []}, config)\n",
    "\n",
    "# Things to try:\n",
    "#  - Just chat! There's no ordering or menu yet.\n",
    "#  - 'q' to exit.\n",
    "\n",
    "pprint(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/agent_supervisor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "@tool(\"google_web_search\")\n",
    "def google_web_search(\n",
    "    query: str,\n",
    "    num_results: int = 5,      \n",
    "    how_many: int = 5,            \n",
    "    style: str = \"friendly\",    \n",
    "    **kwargs,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Search Google (Programmable Search Engine) and return a **summarised list**\n",
    "    of the best places/attractions for the user.\n",
    "\n",
    "    Args:\n",
    "        query: Natural‑language search, e.g. \"best museums in Paris\".\n",
    "        num_results: Raw results fetched from Google (max 10).\n",
    "        how_many: Items to keep after LLM re‑ranking.\n",
    "        style: Output tone (\"friendly\", \"formal\", \"bullet\").\n",
    "    \"\"\"\n",
    "    if not (GOOGLE_SEARCH_KEY and GOOGLE_CSE_ID):\n",
    "        raise RuntimeError(\n",
    "            \"Set GOOGLE_SEARCH_API_KEY and GOOGLE_CSE_ID env vars first.\"\n",
    "        )\n",
    "\n",
    "    # Google Search API ───────────────────────────\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        \"key\": GOOGLE_SEARCH_KEY,\n",
    "        \"cx\":  GOOGLE_CSE_ID,\n",
    "        \"q\":   query,\n",
    "        \"num\": min(num_results, 5),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        raw = requests.get(url, params=params, timeout=10).json()\n",
    "        items: List[Dict] = raw.get(\"items\", [])\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        raise RuntimeError(f\"Google Search error: {e}\")\n",
    "\n",
    "    if not items:\n",
    "        return \"I couldn't find any results for that search.\"\n",
    "\n",
    "    # preparing prompt for LLM ────────────────────────────\n",
    "    compact = [\n",
    "        {\"title\": it[\"title\"], \"link\": it[\"link\"], \"snippet\": it[\"snippet\"]}\n",
    "        for it in items\n",
    "    ]\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are a travel expert.\\n\"\n",
    "        f\"Pick the top {how_many} places someone should visit based on the \"\n",
    "        f\"Google search results below and present them in a {style} style. \"\n",
    "        \"Give each place a one‑sentence description.\\n\\n\"\n",
    "        f\"{json.dumps(compact, ensure_ascii=False, indent=2)}\"\n",
    "    )\n",
    "\n",
    "    # summerization with LLM ───────────────────────────────────\n",
    "    summary = llm.invoke(prompt).content\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Define the tools and create a \"tools\" node.\n",
    "tools = [search_places]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Attach the tools to the model so that it knows what it can call.\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")\n",
    "\n",
    "\n",
    "def maybe_route_to_tools(state: OrderState) -> Literal[\"tools\", \"human\"]:\n",
    "    \"\"\"Route between human or tool nodes, depending if a tool call is made.\"\"\"\n",
    "    if not (msgs := state.get(\"messages\", [])):\n",
    "        raise ValueError(f\"No messages found when parsing state: {state}\")\n",
    "\n",
    "    # Only route based on the last message.\n",
    "    msg = msgs[-1]\n",
    "\n",
    "    # When the chatbot returns tool_calls, route to the \"tools\" node.\n",
    "    if hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"human\"\n",
    "\n",
    "\n",
    "def chatbot_with_tools(state: OrderState) -> OrderState:\n",
    "    \"\"\"The chatbot with tools. A simple wrapper around the model's own chat interface.\"\"\"\n",
    "    defaults = {\"order\": [], \"finished\": False}\n",
    "\n",
    "    if state[\"messages\"]:\n",
    "        new_output = llm_with_tools.invoke([TRIPADVISOR_SYSINT] + state[\"messages\"])\n",
    "    else:\n",
    "        new_output = AIMessage(content=WELCOME_MSG)\n",
    "\n",
    "    # Set up some defaults if not already set, then pass through the provided state,\n",
    "    # overriding only the \"messages\" field.\n",
    "    return defaults | state | {\"messages\": [new_output]}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(OrderState)\n",
    "\n",
    "# Add the nodes, including the new tool_node.\n",
    "graph_builder.add_node(\"chatbot\", chatbot_with_tools)\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "# Chatbot may go to tools, or human.\n",
    "graph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Human may go back to chatbot, or exit.\n",
    "# graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
    "graph_with_menu = graph_builder.compile()\n",
    "\n",
    "Image(graph_with_menu.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Welcome to the TripoBot. Type `q` to quit. What is your dream trip? how much is your budget? what activity do you like to do? Do you like blind trip program?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 49\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:79\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4023:100b::5f%5D:443 {grpc_message:\"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\", grpc_status:8, created_time:\"2025-04-07T21:48:10.381294-07:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_with_menu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2688\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2687\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2688\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   2689\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2690\u001b[0m     config,\n\u001b[1;32m   2691\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   2692\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2693\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2694\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2695\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   2696\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2697\u001b[0m ):\n\u001b[1;32m   2698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2699\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2340\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2334\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2335\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2337\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2338\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   2339\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2340\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2341\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2342\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2343\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2344\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2345\u001b[0m         ):\n\u001b[1;32m   2346\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2347\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   2348\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langgraph/pregel/runner.py:158\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    156\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langgraph/utils/runnable.py:606\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    603\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    604\u001b[0m )\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langgraph/utils/runnable.py:371\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 371\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[133], line 32\u001b[0m, in \u001b[0;36mchatbot_with_tools\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     29\u001b[0m defaults \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 32\u001b[0m     new_output \u001b[38;5;241m=\u001b[39m \u001b[43mllm_with_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTRIPADVISOR_SYSINT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     new_output \u001b[38;5;241m=\u001b[39m AIMessage(content\u001b[38;5;241m=\u001b[39mWELCOME_MSG)\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langchain_core/runnables/base.py:5440\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   5434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5435\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5438\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5439\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5441\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5442\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5443\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:1022\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1019\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m         )\n\u001b[0;32m-> 1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:331\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    327\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    328\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    341\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:894\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    892\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    893\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:719\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    718\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 719\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m         )\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    727\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:960\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 960\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    964\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:1089\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1065\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1077\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m   1078\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m   1079\u001b[0m         messages,\n\u001b[1;32m   1080\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1087\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m   1088\u001b[0m     )\n\u001b[0;32m-> 1089\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:206\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/tenacity/__init__.py:330\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(\n\u001b[1;32m    327\u001b[0m     f, functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__kwdefaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    328\u001b[0m )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/tenacity/__init__.py:467\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/tenacity/__init__.py:368\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    366\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 368\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/tenacity/__init__.py:410\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    408\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/tenacity/__init__.py:183\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/tenacity/__init__.py:470\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    472\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:204\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:188\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:867\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    866\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/google/api_core/retry.py:372\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    369\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    371\u001b[0m )\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/google/api_core/retry.py:207\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    209\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bench1/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:81\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 49\n}\n]"
     ]
    }
   ],
   "source": [
    "state = graph_with_menu.invoke({\"messages\": []}, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
